# CR-18: Multiturn Review ì‹¤í–‰ ë¡œì§ êµ¬í˜„ ëª…ì„¸ì„œ

## ğŸ“‹ ê°œìš”

Linear CR-18 ì´ìŠˆì— ë”°ë¼ LLMì˜ context limitë¥¼ ì´ˆê³¼í•˜ëŠ” ê²½ìš° í”„ë¡¬í”„íŠ¸ë¥¼ ë¶„í• í•˜ì—¬ ë³‘ë ¬ ì²˜ë¦¬í•˜ëŠ” Multiturn Review ê¸°ëŠ¥ì„ êµ¬í˜„í•©ë‹ˆë‹¤.

**ì£¼ìš” ëª©í‘œ:**
- Context limit ì´ˆê³¼ ì‹œ ìë™ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ë¶„í•  ì²˜ë¦¬
- í† í° ì •ë³´ ê¸°ë°˜ ì§€ëŠ¥ì  ë¶„í•  ì „ëµ êµ¬í˜„
- ë³‘ë ¬ API í˜¸ì¶œì„ í†µí•œ ë¹ ë¥¸ ë¦¬ë·° ì²˜ë¦¬
- ë¶„í• ëœ ê²°ê³¼ë“¤ì˜ ê°„ë‹¨í•œ ë³‘í•© (ê³ ë„í™”ëœ í•©ì„±ì€ CR-19ì—ì„œ êµ¬í˜„)

## ğŸ¯ Linear ì´ìŠˆ ì •ë³´

**CR-18: multiturn review ì‹¤í–‰ ë¡œì§ êµ¬í˜„**
- ìš°ì„ ìˆœìœ„: High (2)
- ì¶”ì •: 2 Points  
- ìƒíƒœ: In Review
- ë§ˆê°ì¼: 2025-08-07

**ìš”êµ¬ì‚¬í•­:**
- user promptë¥¼ ë‚˜ëˆ„ì–´ì„œ system promptì™€ í•¨ê»˜ ë³´ë‚´ëŠ” ë¡œì§ êµ¬í˜„
- context limitì„ ì•ˆ ë„˜ë„ë¡ ë¶„ì‚°í•´ì„œ ë³´ëƒ„
- user_promptë¥¼ ë³´ë‚¼ ë•Œ overlap í•„ìš”í•œì§€ íŒë‹¨
- ë³‘ë ¬ ì²˜ë¦¬ í•„ìš” (ë¹ ë¥¸ ë¦¬ë·° ì²˜ë¦¬ë¥¼ ìœ„í•¨)

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ì„¤ê³„

### í˜„ì¬ ì›Œí¬í”Œë¡œìš°
```
ReviewRequest -> PromptGenerator -> ReviewPromptWithFileContent -> BaseGateway.review_code -> ReviewResult
                                                                              â†“ (context limit error)
                                                                         Exception ë°œìƒ
```

### ìƒˆë¡œìš´ Multiturn ì›Œí¬í”Œë¡œìš°
```
ReviewRequest -> PromptGenerator -> ReviewPromptWithFileContent -> BaseGateway.review_code
                                                                              â†“ (context limit error)
                                                                   MultiturnReviewExecutor
                                                                              â†“
                                                        PromptSplitter (í† í° ê¸°ë°˜ ë¶„í• )
                                                                              â†“
                                                        ë³‘ë ¬ API í˜¸ì¶œ (multiple BaseGateway.review_code)
                                                                              â†“
                                                        ê°„ë‹¨í•œ ê²°ê³¼ ë³‘í•© (CR-19ì—ì„œ ê³ ë„í™”)
                                                                              â†“
                                                                        ìµœì¢… ReviewResult
```

## ğŸ—‚ï¸ êµ¬í˜„ ëŒ€ìƒ íŒŒì¼

### ìˆ˜ì • ëŒ€ìƒ íŒŒì¼

#### `selvage/cli.py`
**ìœ„ì¹˜:** L391-398  
**í˜„ì¬ ì½”ë“œ:**
```python
if error_response.is_context_limit_error():
    console.error(
        f"ì»¨í…ìŠ¤íŠ¸ ì œí•œ ì´ˆê³¼: {error_response.error_message}\n"
        f"í–¥í›„ Multiturn ë¦¬ë·° ê¸°ëŠ¥ìœ¼ë¡œ ìë™ ì¬ì‹œë„ë  ì˜ˆì •ì…ë‹ˆë‹¤."
    )
    # TODO: Multiturn ë¦¬ë·° êµ¬í˜„ í›„ ì—¬ê¸°ì„œ ì¬ì‹œë„
    raise Exception(
        f"Context limit exceeded: {error_response.error_message}"
    )
```

**ìˆ˜ì • í›„:**
```python
if error_response.is_context_limit_error():
    console.info("ì»¨í…ìŠ¤íŠ¸ ì œí•œ ì´ˆê³¼ ê°ì§€, Multiturn ë¦¬ë·° ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
    
    # Multiturn ë¦¬ë·° ì‹¤í–‰ (ì´ë¯¸ ìƒì„±ëœ review_prompt ì‚¬ìš©)
    multiturn_executor = MultiturnReviewExecutor()
    review_result = multiturn_executor.execute_multiturn_review(
        review_prompt=review_prompt,  # L383ì—ì„œ ì´ë¯¸ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        error_response=error_response,
        llm_gateway=llm_gateway
    )
    
    return review_result.review_response, review_result.estimated_cost
```

### ì‹ ê·œ ìƒì„± íŒŒì¼

#### `selvage/src/multiturn/__init__.py`
- MultiturnReviewExecutor, PromptSplitter í´ë˜ìŠ¤ export

#### `selvage/src/multiturn/multiturn_review_executor.py`
- ë©”ì¸ ì‹¤í–‰ ë¡œì§ ë‹´ë‹¹
- í”„ë¡¬í”„íŠ¸ ë¶„í• , ë³‘ë ¬ ì²˜ë¦¬, ê²°ê³¼ í•©ì„± ì¡°ìœ¨

#### `selvage/src/multiturn/prompt_splitter.py`  
- í† í° ì •ë³´ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ë¶„í•  ë¡œì§
- Gemini ë“± í† í° ì •ë³´ ë¯¸ì œê³µ provider ëŒ€ì‘


## ğŸ”§ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì¸í„°í˜ì´ìŠ¤

### 1. MultiturnReviewExecutor

```python
class MultiturnReviewExecutor:
    """Multiturn Review ë©”ì¸ ì‹¤í–‰ê¸°"""
    
    def execute_multiturn_review(
        self, 
        review_prompt: ReviewPromptWithFileContent,
        error_response: ErrorResponse,
        llm_gateway: BaseGateway
    ) -> ReviewResult:
        """
        Context limit ì´ˆê³¼ ì‹œ í”„ë¡¬í”„íŠ¸ë¥¼ ë¶„í• í•˜ì—¬ ë³‘ë ¬ ì²˜ë¦¬ í›„ ê²°ê³¼ í•©ì„±
        
        Args:
            review_prompt: ì´ë¯¸ ìƒì„±ëœ ë¦¬ë·° í”„ë¡¬í”„íŠ¸ (cli.py:L383ì—ì„œ ìƒì„±)
            error_response: Context limit ì—ëŸ¬ ì •ë³´ (í† í° ì •ë³´ í¬í•¨)
            llm_gateway: LLM API í˜¸ì¶œ ê²Œì´íŠ¸ì›¨ì´
            
        Returns:
            ReviewResult: í•©ì„±ëœ ìµœì¢… ë¦¬ë·° ê²°ê³¼
        """
        # Pseudo code:
        # 1. í† í° ì •ë³´ ì¶”ì¶œ (actual_tokens, max_tokens)
        # 2. user_prompts ë¶„í•  (system_promptëŠ” ê³µí†µ ì‚¬ìš©)
        # 3. ë³‘ë ¬ API í˜¸ì¶œ
        # 4. ê²°ê³¼ ê°„ë‹¨ ë³‘í•© (ìƒì„¸ í•©ì„±ì€ CR-19ì—ì„œ êµ¬í˜„)
        pass
```

### 2. PromptSplitter

```python
class PromptSplitter:
    """í”„ë¡¬í”„íŠ¸ ë¶„í•  ë‹´ë‹¹ í´ë˜ìŠ¤"""
    
    def split_user_prompts(
        self,
        user_prompts: list[UserPromptWithFileContent],
        actual_tokens: int | None,
        max_tokens: int | None,
        overlap: int = 1
    ) -> list[list[UserPromptWithFileContent]]:
        """
        í† í° ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ user_promptsë¥¼ ë¶„í• 
        
        Args:
            user_prompts: ë¶„í• í•  ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ëª©ë¡
            actual_tokens: ì‹¤ì œ ì‚¬ìš©í•œ í† í° ìˆ˜ (error_responseì—ì„œ ì¶”ì¶œ)
            max_tokens: ìµœëŒ€ í—ˆìš© í† í° ìˆ˜ (error_responseì—ì„œ ì¶”ì¶œ)
            overlap: ë¶„í• ëœ ì²­í¬ê°„ ê²¹ì¹˜ëŠ” íŒŒì¼ ê°œìˆ˜ (ê¸°ë³¸ê°’: 1)
            
        Returns:
            ë¶„í• ëœ user_prompts ê·¸ë£¹ë“¤ì˜ ëª©ë¡
            
        ë¶„í•  ì „ëµ:
        - í† í° ì •ë³´ ìˆìŒ: actual_tokensê³¼ max_tokens ë¹„ìœ¨ë¡œ ê³„ì‚°í•˜ì—¬ ë¶„í• 
        - í† í° ì •ë³´ ì—†ìŒ: ì„ì˜ë¡œ ë°˜ìœ¼ë¡œ ë¶„í•  (Gemini ë“±)
        - overlap ì ìš©: ê° ì²­í¬ì— overlap ê°œìˆ˜ë§Œí¼ ì´ì „ ì²­í¬ì˜ ë§ˆì§€ë§‰ íŒŒì¼ë“¤ í¬í•¨
        """
        pass
    
    def _calculate_split_ratio(self, actual_tokens: int, max_tokens: int) -> int:
        """ë¶„í•  ë¹„ìœ¨ ê³„ì‚°"""
        pass
    
    def _apply_overlap(
        self, 
        chunks: list[list[UserPromptWithFileContent]], 
        overlap: int
    ) -> list[list[UserPromptWithFileContent]]:
        """ë¶„í• ëœ ì²­í¬ì— overlap ì ìš©"""
        pass
```


## ğŸ’¡ êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

### í† í° ì •ë³´ ì¶”ì¶œ ë¡œì§

```python
def extract_token_info(error_response: ErrorResponse) -> tuple[int | None, int | None]:
    """
    ErrorResponseì—ì„œ í† í° ì •ë³´ ì¶”ì¶œ
    
    Returns:
        (actual_tokens, max_tokens) íŠœí”Œ
        í† í° ì •ë³´ê°€ ì—†ìœ¼ë©´ (None, None) ë°˜í™˜
    """
    actual_tokens = error_response.raw_error.get("actual_tokens")
    max_tokens = error_response.raw_error.get("max_tokens")
    
    return (
        int(actual_tokens) if actual_tokens else None,
        int(max_tokens) if max_tokens else None
    )
```

### ë¶„í•  ì „ëµ

#### í† í° ì •ë³´ ê¸°ë°˜ ë¶„í• 
```python
# ì˜ˆì‹œ: actual_tokens=150000, max_tokens=100000ì¸ ê²½ìš°
split_ratio = math.ceil(actual_tokens / (max_tokens * 0.8))  # ì—¬ìœ ë¶„ 20% í™•ë³´
# split_ratio = 2 (2ê°œë¡œ ë¶„í• )

# user_promptsë¥¼ split_ratio ê°œìˆ˜ë§Œí¼ ê· ë“± ë¶„í• 
chunks = []
chunk_size = len(user_prompts) // split_ratio
for i in range(0, len(user_prompts), chunk_size):
    chunks.append(user_prompts[i:i + chunk_size])

# overlap ì ìš©
overlap = 1
if overlap > 0 and len(chunks) > 1:
    for i in range(1, len(chunks)):
        # ì´ì „ ì²­í¬ì˜ ë§ˆì§€ë§‰ overlap ê°œìˆ˜ë§Œí¼ í˜„ì¬ ì²­í¬ ì•ì— ì¶”ê°€
        prev_chunk = chunks[i-1]
        if len(prev_chunk) >= overlap:
            overlap_items = prev_chunk[-overlap:]
            chunks[i] = overlap_items + chunks[i]
```

#### í† í° ì •ë³´ ë¯¸ì œê³µ ì‹œ ê¸°ë³¸ ë¶„í• 
```python
# Gemini ë“± í† í° ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•ŠëŠ” ê²½ìš°
# ì„ì˜ë¡œ ë°˜ìœ¼ë¡œ ë¶„í• 
mid_point = len(user_prompts) // 2
chunk1 = user_prompts[:mid_point]
chunk2 = user_prompts[mid_point:]
chunks = [chunk1, chunk2]

# overlap ì ìš©
overlap = 1
if overlap > 0 and len(chunk1) >= overlap:
    overlap_items = chunk1[-overlap:]
    chunk2 = overlap_items + chunk2
    chunks = [chunk1, chunk2]
```

### ë³‘ë ¬ ì²˜ë¦¬ êµ¬í˜„

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

async def parallel_review(
    self, 
    split_prompts: list[list[UserPromptWithFileContent]],
    system_prompt: SystemPrompt,
    llm_gateway: BaseGateway
) -> list[ReviewResult]:
    """
    ë¶„í• ëœ í”„ë¡¬í”„íŠ¸ë“¤ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬
    """
    async def review_single_chunk(user_prompts_chunk: list[UserPromptWithFileContent]):
        review_prompt = ReviewPromptWithFileContent(
            system_prompt=system_prompt,
            user_prompts=user_prompts_chunk
        )
        return llm_gateway.review_code(review_prompt)
    
    # ë³‘ë ¬ ì‹¤í–‰
    tasks = [review_single_chunk(chunk) for chunk in split_prompts]
    results = await asyncio.gather(*tasks)
    
    return results
```


## ğŸ§ª í…ŒìŠ¤íŠ¸ ì „ëµ

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

#### `test_prompt_splitter.py`
- í† í° ì •ë³´ ê¸°ë°˜ ë¶„í•  ë¡œì§ í…ŒìŠ¤íŠ¸
- í† í° ì •ë³´ ì—†ì„ ë•Œ ê¸°ë³¸ ë¶„í•  í…ŒìŠ¤íŠ¸
- overlap íŒŒë¼ë¯¸í„°ë³„ ë¶„í•  ê²°ê³¼ í…ŒìŠ¤íŠ¸ (overlap=0,1,2)
- ë¶„í•  ë¹„ìœ¨ ê³„ì‚° ë¡œì§ í…ŒìŠ¤íŠ¸


#### `test_multiturn_review_executor.py`
- ì „ì²´ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸
- ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸

### í†µí•© í…ŒìŠ¤íŠ¸

#### `test_multiturn_integration.py`
- ì‹¤ì œ context limit ì´ˆê³¼ ìƒí™© ëª¨ì˜
- CLIì—ì„œ multiturn review íŠ¸ë¦¬ê±° í…ŒìŠ¤íŠ¸
- ë³‘ë ¬ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

## ğŸ“Š ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­

### ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
- ë™ì‹œ API í˜¸ì¶œ ìˆ˜ ì œí•œ (rate limit ê³ ë ¤)
- ì‹¤íŒ¨í•œ ìš”ì²­ì˜ ì¬ì‹œë„ ë¡œì§
- íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- ëŒ€ìš©ëŸ‰ diff ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
- ë¶„í• ëœ ê²°ê³¼ì˜ ì„ì‹œ ì €ì¥ ì „ëµ

### ë¹„ìš© ìµœì í™”  
- ë¶ˆí•„ìš”í•œ ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
- í•©ì„± ë‹¨ê³„ì˜ í† í° ì‚¬ìš©ëŸ‰ ìµœì†Œí™”

## ğŸš€ êµ¬í˜„ ìˆœì„œ

1. **Phase 1: í•µì‹¬ í´ë˜ìŠ¤ êµ¬í˜„**
   - PromptSplitter ê¸°ë³¸ ë¡œì§
   - MultiturnReviewExecutor í”„ë ˆì„ì›Œí¬

2. **Phase 2: CLI í†µí•©**
   - `selvage/cli.py` ìˆ˜ì •
   - ê¸°ë³¸ ë™ì‘ ê²€ì¦

3. **Phase 3: ê³ ë„í™”**
   - ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
   - ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
   - ì„±ëŠ¥ íŠœë‹

4. **Phase 4: í…ŒìŠ¤íŠ¸ ë° ê²€ì¦**
   - ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
   - í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±
   - ì‹¤ì œ í™˜ê²½ì—ì„œ ê²€ì¦

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] `selvage/src/multiturn/` íŒ¨í‚¤ì§€ ìƒì„±
- [ ] MultiturnReviewExecutor í´ë˜ìŠ¤ êµ¬í˜„
- [ ] PromptSplitter í´ë˜ìŠ¤ êµ¬í˜„  
- [ ] CLI í†µí•© (`selvage/cli.py` ìˆ˜ì •)
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] ì‹¤ì œ context limit ìƒí™©ì—ì„œ ë™ì‘ ê²€ì¦
- [ ] ì„±ëŠ¥ ë° ë¹„ìš© ìµœì í™”
- [ ] ë¬¸ì„œí™” ì—…ë°ì´íŠ¸

## ğŸ”— ê´€ë ¨ ì´ìŠˆ

- **Linear CR-18**: multiturn review ì‹¤í–‰ ë¡œì§ êµ¬í˜„
- **Linear CR-19**: synthesize ë¡œì§ êµ¬í˜„ (í›„ì† ì´ìŠˆ)
- **Linear CR-17**: í† í° ê²€ì¦ ë°©ì‹ ê°œì„  (ì„ í–‰ ì‘ì—…)