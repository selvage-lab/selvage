# 지원하는 LLM 모델 설정
# 새 모델 추가시 이 파일만 수정하면 됩니다.

models:
  gpt-5:
    full_name: "gpt-5"
    aliases: ["gpt-5-medium"]
    description: "OpenAI의 최신 통합 모델로 고급 추론과 빠른 응답을 결합"
    provider: "openai"
    params:
      reasoning_effort: "medium"
    thinking_mode: false
    pricing:
      input: 1.25 # $1.25/1M tokens (공식)
      output: 10.0 # $10.00/1M tokens (공식)
      description: "$1.25/$10.00 per 1M tokens"
    context_limit: 400000
    openrouter_name: "openai/gpt-5"
    openrouter_params:
      reasoning:
        effort: "medium"

  gpt-5-high:
    full_name: "gpt-5"
    aliases: ["gpt-5-high"]
    description: "최고 수준의 추론 능력으로 복잡한 코드 분석 및 문제 해결 수행"
    provider: "openai"
    params:
      reasoning_effort: "high"
    thinking_mode: false
    pricing:
      input: 1.25
      output: 10.0
      description: "$1.25/$10.00 per 1M tokens"
    context_limit: 400000
    openrouter_name: "openai/gpt-5"
    openrouter_params:
      reasoning:
        effort: "high"

  gpt-5-mini:
    full_name: "gpt-5-mini"
    aliases: ["gpt-5-mini"]
    description: "경량화된 GPT-5 모델로 빠른 응답과 비용 효율성 제공"
    provider: "openai"
    params:
      reasoning_effort: "medium"
    thinking_mode: false
    pricing:
      input: 0.25 # $0.25/1M tokens (공식)
      output: 2.0 # $2.00/1M tokens (공식)
      description: "$0.25/$2.00 per 1M tokens"
    context_limit: 400000
    openrouter_name: "openai/gpt-5-mini"
    openrouter_params:
      reasoning:
        effort: "medium"

  claude-sonnet-4-20250514:
    full_name: "claude-sonnet-4-20250514"
    aliases: ["claude-sonnet-4"]
    description: "하이브리드 추론 모델로 고급 코딩 및 명령 수행 최적화"
    provider: "anthropic"
    params:
      temperature: 0.0
    thinking_mode: false
    max_output_tokens: 8192
    pricing:
      input: 3.0
      output: 15.0
      description: "$3.00/$15.00 per 1M tokens"
    context_limit: 200000
    openrouter_name: "anthropic/claude-sonnet-4"
    openrouter_params:
      temperature: 0.0

  claude-sonnet-4-20250514-thinking:
    full_name: "claude-sonnet-4-20250514"
    aliases: ["claude-sonnet-4-thinking"]
    description: "(recommend) 하이브리드 추론 모델로 확장 사고 프로세스 지원"
    provider: "anthropic"
    params:
      temperature: 1 # thinking 모드에서 더 다양한 사고 과정 생성을 위해 설정
      thinking:
        type: "enabled"
        budget_tokens: 20000
    thinking_mode: true
    max_output_tokens: 48000
    pricing:
      input: 3.0
      output: 15.0
      description: "$3.00/$15.00 per 1M tokens"
    context_limit: 200000
    openrouter_name: "anthropic/claude-sonnet-4"
    openrouter_params:
      temperature: 1
      reasoning:
        max_tokens: 20000

  gemini-2.5-pro:
    full_name: "gemini-2.5-pro"
    aliases: ["gemini-2.5-pro"]
    description: "(recommend) 대용량 컨텍스트 처리 및 고급 추론 작업 수행"
    provider: "google"
    params:
      temperature: 0.0
    thinking_mode: false
    pricing:
      input: 1.25
      output: 10.0
      description: "$1.25/$10.00 per 1M tokens (Gemini 2.5 Pro)"
    context_limit: 1048576
    openrouter_name: "google/gemini-2.5-pro"
    openrouter_params:
      temperature: 0.0

  gemini-2.5-flash:
    full_name: "gemini-2.5-flash"
    aliases: ["gemini-2.5-flash"]
    description: "(recommend) 응답 속도와 비용 효율성 최적화 모델"
    provider: "google"
    params:
      temperature: 0.0
    thinking_mode: false
    pricing:
      input: 0.15
      output: 0.6
      description: "$0.15/$0.60 per 1M tokens (Gemini 2.5 Flash)"
    context_limit: 1048576
    openrouter_name: "google/gemini-2.5-flash"
    openrouter_params:
      temperature: 0.0

  kimi-k2:
    full_name: "kimi-k2"
    aliases: ["kimi-k2"]
    description: "Moonshot AI의 대용량 컨텍스트 처리 모델"
    provider: "openrouter"
    params:
      temperature: 0.0
    thinking_mode: false
    pricing:
      input: 0.14
      output: 2.49
      description: "$0.14/$2.49 per 1M tokens"
    context_limit: 131000
    openrouter_name: "moonshotai/kimi-k2"
    openrouter_params:
      temperature: 0.0

  kimi-k2-free:
    full_name: "kimi-k2-free"
    aliases: ["kimi-k2-free"]
    description: "Moonshot AI의 대용량 컨텍스트 처리 모델 (무료)"
    provider: "openrouter"
    params:
      temperature: 0.0
    thinking_mode: false
    pricing:
      input: 0.0
      output: 0.0
      description: "Free tier"
    context_limit: 32768
    openrouter_name: "moonshotai/kimi-k2:free"
    openrouter_params:
      temperature: 0.0

  deepseek-v3-0324:
    full_name: "deepseek-v3-0324"
    aliases: ["deepseek-v3-0324"]
    description: "DeepSeek의 고급 대화 모델 v3.0"
    provider: "openrouter"
    params:
      temperature: 0.0
    thinking_mode: false
    pricing:
      input: 0.25
      output: 0.85
      description: "$0.25/$0.85 per 1M tokens"
    context_limit: 163840
    openrouter_name: "deepseek/deepseek-chat-v3-0324"
    openrouter_params:
      temperature: 0.0

  deepseek-v3-0324-free:
    full_name: "deepseek-v3-0324-free"
    aliases: ["deepseek-v3-0324-free"]
    description: "DeepSeek의 고급 대화 모델 v3.0 (무료)"
    provider: "openrouter"
    openrouter_params:
      temperature: 0.0
    params:
      temperature: 0.0
    thinking_mode: false
    pricing:
      input: 0.0
      output: 0.0
      description: "Free tier"
    context_limit: 32768
    openrouter_name: "deepseek/deepseek-chat-v3-0324:free"

  deepseek-r1-0528:
    full_name: "deepseek-r1-0528"
    aliases: ["deepseek-r1-0528"]
    description: "DeepSeek의 추론 특화 모델 R1"
    provider: "openrouter"
    params:
      temperature: 0.0
    thinking_mode: false
    pricing:
      input: 0.272
      output: 0.272
      description: "$0.272/$0.272 per 1M tokens"
    context_limit: 163840
    openrouter_name: "deepseek/deepseek-r1-0528"
    openrouter_params:
      temperature: 0.0

  deepseek-r1-0528-free:
    full_name: "deepseek-r1-0528-free"
    aliases: ["deepseek-r1-0528-free"]
    description: "DeepSeek의 추론 특화 모델 R1 (무료)"
    provider: "openrouter"
    params:
      temperature: 0.0
    thinking_mode: false
    pricing:
      input: 0.0
      output: 0.0
      description: "Free tier"
    context_limit: 163840
    openrouter_name: "deepseek/deepseek-r1-0528:free"
    openrouter_params:
      temperature: 0.0

  qwen3-coder:
    full_name: "qwen3-coder"
    aliases: ["qwen3-coder"]
    description: "Qwen의 코더 모델"
    provider: "openrouter"
    params:
      temperature: 0.0
    thinking_mode: false
    pricing:
      input: 1.0
      output: 5.0
      description: "$1.00/$5.00 per 1M tokens"
    context_limit: 262144
    openrouter_name: "qwen/qwen3-coder"
    openrouter_params:
      temperature: 0.0

  qwen3-coder-free:
    full_name: "qwen3-coder-free"
    aliases: ["qwen3-coder-free"]
    description: "Qwen의 코더 모델 (무료)"
    provider: "openrouter"
    params:
      temperature: 0.0
    thinking_mode: false
    pricing:
      input: 0.0
      output: 0.0
      description: "Free tier"
    context_limit: 32000
    openrouter_name: "qwen/qwen3-coder:free"
    openrouter_params:
      temperature: 0.0
