"""
Context Limit ì—ëŸ¬ ì²˜ë¦¬ í†µí•© í…ŒìŠ¤íŠ¸

ì‹¤ì œ ì½”ë“œ ë¦¬ë·° ì›Œí¬í”Œë¡œìš°ë¥¼ í†µí•´ context limitì„ ì´ˆê³¼í–ˆì„ ë•Œ
ErrorPatternParserì™€ ReviewResultê°€ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•˜ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.

ì‹¤í–‰ ë°©ë²•:
    pytest tests/test_context_limit_workflow_integration.py -v -s

ì£¼ì˜ì‚¬í•­:
    - ì‹¤ì œ APIë¥¼ í˜¸ì¶œí•˜ë¯€ë¡œ ë¹„ìš©ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
    - ê° providerì˜ API keyê°€ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
"""

import os

import pytest

from selvage.src.llm_gateway.gateway_factory import GatewayFactory
from selvage.src.utils.prompts.models import (
    FileContextInfo,
    ReviewPromptWithFileContent,
    SystemPrompt,
    UserPromptWithFileContent,
)


class ContextLimitWorkflowTester:
    """Context limit ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ í´ë˜ìŠ¤"""

    def create_oversized_content(self, context_limit_tokens: int) -> str:
        """Context limitì„ í™•ì‹¤íˆ ì´ˆê³¼í•˜ëŠ” ë§¤ìš° ê¸´ ì½”ë“œ ë‚´ìš©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        # context limitì˜ 200% ìˆ˜ì¤€ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ í™•ì‹¤íˆ ì´ˆê³¼
        target_tokens = int(context_limit_tokens * 2.0)

        # ëŒ€ëµì ì¸ í† í° ê³„ì‚°: í‰ê· ì ìœ¼ë¡œ 1 í† í° = 4 ê¸€ìë¡œ ê°€ì •
        chars_per_token = 4
        target_chars = target_tokens * chars_per_token

        # ë§¤ìš° ê¸´ ì½”ë“œ ë‚´ìš© ìƒì„±
        base_code = """def complex_function_{index}(a, b, c, d, e, f):
    '''ë§¤ìš° ë³µì¡í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤'''
    result = 0
    for i in range(1000):
        temp = a * b + c * d - e * f
        result += temp * i
        if result > 10000:
            result = result % 10000
    return result

class DataProcessor_{index}:
    def __init__(self, data):
        self.data = data
        self.results = []
    
    def process(self):
        for item in self.data:
            processed = self.transform(item)
            self.results.append(processed)
    
    def transform(self, item):
        return {{
            'value': item.get('value', 0) * 2,
            'name': item.get('name', '').upper(),
            'processed_at': 'now'
        }}

"""

        # ê¸´ ì½”ë“œ ë‚´ìš© ìƒì„±
        long_code = ""
        index = 0
        while len(long_code) < target_chars:
            long_code += base_code.format(index=index)
            index += 1

        return long_code

    def create_oversized_review_prompt(
        self, context_limit_tokens: int
    ) -> ReviewPromptWithFileContent:
        """Context limitì„ ì´ˆê³¼í•˜ëŠ” ReviewPromptWithFileContentë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""

        # í° ì½”ë“œ ë‚´ìš© ìƒì„±
        oversized_code = self.create_oversized_content(context_limit_tokens)

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_prompt = SystemPrompt(
            role="system",
            content="ë‹¤ìŒ ì½”ë“œë¥¼ ìì„¸íˆ ë¦¬ë·°í•´ì£¼ì„¸ìš”. ëª¨ë“  í•¨ìˆ˜ì™€ í´ë˜ìŠ¤ì— ëŒ€í•´ ìƒì„¸í•œ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.",
        )

        # íŒŒì¼ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        file_context = FileContextInfo.create_full_context(oversized_code)

        # UserPromptWithFileContent ìƒì„± (ë¹ˆ hunks ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©)
        user_prompt = UserPromptWithFileContent(
            file_name="test_large_file.py",
            file_context=file_context,
            hunks=[],  # ë¹ˆ hunksë¡œ ì„¤ì •
            language="python",
        )

        return ReviewPromptWithFileContent(
            system_prompt=system_prompt, user_prompts=[user_prompt]
        )


# ì „ì—­ í…ŒìŠ¤í„° ì¸ìŠ¤í„´ìŠ¤
tester = ContextLimitWorkflowTester()


def test_openai_context_limit_workflow():
    """OpenAI APIì˜ context limit ì—ëŸ¬ë¥¼ ì‹¤ì œ ì›Œí¬í”Œë¡œìš°ë¡œ ê²€ì¦í•©ë‹ˆë‹¤."""
    if not os.getenv("OPENAI_API_KEY"):
        pytest.skip("OPENAI_API_KEY not found")

    model_name = "gpt-5"
    context_limit = 1000000

    print("\\n=== OpenAI Context Limit ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ===")
    print(f"ëª¨ë¸: {model_name}")
    print(f"Context Limit: {context_limit:,} tokens")

    try:
        # ì‹¤ì œ ì›Œí¬í”Œë¡œìš°ì™€ ë™ì¼í•˜ê²Œ gateway ìƒì„±
        gateway = GatewayFactory.create(model=model_name)

        # Context limitì„ ì´ˆê³¼í•˜ëŠ” review prompt ìƒì„±
        review_prompt = tester.create_oversized_review_prompt(context_limit)

        print(
            f"í”„ë¡¬í”„íŠ¸ í¬ê¸°: ì•½ {len(review_prompt.to_combined_text()) // 4:,} tokens ì¶”ì •"
        )

        # ì‹¤ì œ ì½”ë“œ ë¦¬ë·° ì›Œí¬í”Œë¡œìš° ìˆ˜í–‰
        review_result = gateway.review_code(review_prompt)

        # ê²°ê³¼ ê²€ì¦
        print("\\nğŸ“Š ê²€ì¦ ê²°ê³¼:")
        print(f"   success: {review_result.success}")
        print(f"   error_response: {review_result.error_response}")

        if review_result.error_response:
            print(f"   error_type: {review_result.error_response.error_type}")
            print(
                f"   error_message: {review_result.error_response.error_message[:100]}..."
            )

        # ê²€ì¦: ì‹¤íŒ¨í•´ì•¼ í•˜ê³ , context limit ì—ëŸ¬ë¡œ ì‹ë³„ë˜ì–´ì•¼ í•¨
        assert review_result.success is False, (
            "Context limit ì´ˆê³¼ ì‹œ success=Falseì—¬ì•¼ í•©ë‹ˆë‹¤"
        )
        assert review_result.error_response is not None, "ì—ëŸ¬ ì‘ë‹µì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤"
        # ì—ëŸ¬ íƒ€ì… ê²€ì¦ - context limit ì—ëŸ¬ë¡œ ì—„ê²©í•˜ê²Œ ì‹ë³„
        assert review_result.error_response.error_type == "context_limit_exceeded", (
            f"ì—ëŸ¬ íƒ€ì…ì´ 'context_limit_exceeded'ì—¬ì•¼ í•©ë‹ˆë‹¤. "
            f"ì‹¤ì œ: {review_result.error_response.error_type}"
        )

        print("âœ… OpenAI Context Limit ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì„±ê³µ!")

    except Exception as e:
        pytest.fail(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜ˆì™¸ ë°œìƒ: {e}")


def test_anthropic_context_limit_workflow():
    """Anthropic APIì˜ context limit ì—ëŸ¬ë¥¼ ì‹¤ì œ ì›Œí¬í”Œë¡œìš°ë¡œ ê²€ì¦í•©ë‹ˆë‹¤."""
    if not os.getenv("ANTHROPIC_API_KEY"):
        pytest.skip("ANTHROPIC_API_KEY not found")

    model_name = "claude-sonnet-4"
    context_limit = 2000000

    print("\\n=== Anthropic Context Limit ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ===")
    print(f"ëª¨ë¸: {model_name}")
    print(f"Context Limit: {context_limit:,} tokens")

    try:
        # ì‹¤ì œ ì›Œí¬í”Œë¡œìš°ì™€ ë™ì¼í•˜ê²Œ gateway ìƒì„±
        gateway = GatewayFactory.create(model=model_name)

        # Context limitì„ ì´ˆê³¼í•˜ëŠ” review prompt ìƒì„±
        review_prompt = tester.create_oversized_review_prompt(context_limit)

        print(
            f"í”„ë¡¬í”„íŠ¸ í¬ê¸°: ì•½ {len(review_prompt.to_combined_text()) // 4:,} tokens ì¶”ì •"
        )

        # ì‹¤ì œ ì½”ë“œ ë¦¬ë·° ì›Œí¬í”Œë¡œìš° ìˆ˜í–‰
        review_result = gateway.review_code(review_prompt)

        # ê²°ê³¼ ê²€ì¦
        print("\\nğŸ“Š ê²€ì¦ ê²°ê³¼:")
        print(f"   success: {review_result.success}")
        print(f"   error_response: {review_result.error_response}")

        if review_result.error_response:
            print(f"   error_type: {review_result.error_response.error_type}")
            print(
                f"   error_message: {review_result.error_response.error_message[:100]}..."
            )

        # ê²€ì¦: ì‹¤íŒ¨í•´ì•¼ í•˜ê³ , ì—ëŸ¬ ì‘ë‹µì´ ìˆì–´ì•¼ í•¨
        assert review_result.success is False, (
            "Context limit ì´ˆê³¼ ì‹œ success=Falseì—¬ì•¼ í•©ë‹ˆë‹¤"
        )
        assert review_result.error_response is not None, "ì—ëŸ¬ ì‘ë‹µì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤"
        # ì—ëŸ¬ íƒ€ì… ê²€ì¦ - context limit ì—ëŸ¬ë¡œ ì—„ê²©í•˜ê²Œ ì‹ë³„
        assert review_result.error_response.error_type == "context_limit_exceeded", (
            f"ì—ëŸ¬ íƒ€ì…ì´ 'context_limit_exceeded'ì—¬ì•¼ í•©ë‹ˆë‹¤. "
            f"ì‹¤ì œ: {review_result.error_response.error_type}"
        )

        print("âœ… Anthropic Context Limit ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì„±ê³µ!")

    except Exception as e:
        pytest.fail(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜ˆì™¸ ë°œìƒ: {e}")


@pytest.mark.parametrize(
    "model_name,context_limit",
    [
        ("qwen3-coder", 1000000),
        ("kimi-k2", 200000),
    ],
)
def test_openrouter_context_limit_workflow(model_name, context_limit):
    """OpenRouter APIì˜ context limit ì—ëŸ¬ë¥¼ ì‹¤ì œ ì›Œí¬í”Œë¡œìš°ë¡œ ê²€ì¦í•©ë‹ˆë‹¤."""
    if not os.getenv("OPENROUTER_API_KEY"):
        pytest.skip("OPENROUTER_API_KEY not found")

    print(f"\\n=== OpenRouter ({model_name}) Context Limit ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ===")
    print(f"ëª¨ë¸: {model_name}")
    print(f"Context Limit: {context_limit:,} tokens")

    try:
        # ì‹¤ì œ ì›Œí¬í”Œë¡œìš°ì™€ ë™ì¼í•˜ê²Œ gateway ìƒì„±
        gateway = GatewayFactory.create(model=model_name)

        # Context limitì„ ì´ˆê³¼í•˜ëŠ” review prompt ìƒì„±
        review_prompt = tester.create_oversized_review_prompt(context_limit)

        print(
            f"í”„ë¡¬í”„íŠ¸ í¬ê¸°: ì•½ {len(review_prompt.to_combined_text()) // 4:,} tokens ì¶”ì •"
        )

        # ì‹¤ì œ ì½”ë“œ ë¦¬ë·° ì›Œí¬í”Œë¡œìš° ìˆ˜í–‰
        review_result = gateway.review_code(review_prompt)

        # ê²°ê³¼ ê²€ì¦
        print("\\nğŸ“Š ê²€ì¦ ê²°ê³¼:")
        print(f"   success: {review_result.success}")
        print(f"   error_response: {review_result.error_response}")

        if review_result.error_response:
            print(f"   error_type: {review_result.error_response.error_type}")
            print(
                f"   error_message: {review_result.error_response.error_message[:100]}..."
            )

        # ê²€ì¦: ì‹¤íŒ¨í•´ì•¼ í•˜ê³ , ì—ëŸ¬ ì‘ë‹µì´ ìˆì–´ì•¼ í•¨
        assert review_result.success is False, (
            "Context limit ì´ˆê³¼ ì‹œ success=Falseì—¬ì•¼ í•©ë‹ˆë‹¤"
        )
        assert review_result.error_response is not None, "ì—ëŸ¬ ì‘ë‹µì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤"
        # ì—ëŸ¬ íƒ€ì… ê²€ì¦ - context limit ì—ëŸ¬ë¡œ ì—„ê²©í•˜ê²Œ ì‹ë³„
        assert review_result.error_response.error_type == "context_limit_exceeded", (
            f"ì—ëŸ¬ íƒ€ì…ì´ 'context_limit_exceeded'ì—¬ì•¼ í•©ë‹ˆë‹¤. "
            f"ì‹¤ì œ: {review_result.error_response.error_type}"
        )

        print(f"âœ… OpenRouter ({model_name}) Context Limit ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì„±ê³µ!")

    except Exception as e:
        pytest.fail(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜ˆì™¸ ë°œìƒ: {e}")


def test_google_context_limit_workflow():
    """Google Gemini APIì˜ context limit ì—ëŸ¬ë¥¼ ì‹¤ì œ ì›Œí¬í”Œë¡œìš°ë¡œ ê²€ì¦í•©ë‹ˆë‹¤."""
    if not os.getenv("GEMINI_API_KEY"):
        pytest.skip("GEMINI_API_KEY not found")

    model_name = "gemini-2.5-flash"
    context_limit = 1048576  # Geminiì˜ ë†’ì€ context limit

    print("\\n=== Google Gemini Context Limit ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ===")
    print(f"ëª¨ë¸: {model_name}")
    print(f"Context Limit: {context_limit:,} tokens")

    try:
        # ì‹¤ì œ ì›Œí¬í”Œë¡œìš°ì™€ ë™ì¼í•˜ê²Œ gateway ìƒì„±
        gateway = GatewayFactory.create(model=model_name)

        # Context limitì„ ì´ˆê³¼í•˜ëŠ” review prompt ìƒì„±
        review_prompt = tester.create_oversized_review_prompt(context_limit)

        print(
            f"í”„ë¡¬í”„íŠ¸ í¬ê¸°: ì•½ {len(review_prompt.to_combined_text()) // 4:,} tokens ì¶”ì •"
        )

        # ì‹¤ì œ ì½”ë“œ ë¦¬ë·° ì›Œí¬í”Œë¡œìš° ìˆ˜í–‰
        review_result = gateway.review_code(review_prompt)

        # ê²°ê³¼ ê²€ì¦
        print("\\nğŸ“Š ê²€ì¦ ê²°ê³¼:")
        print(f"   success: {review_result.success}")
        print(f"   error_response: {review_result.error_response}")

        if review_result.error_response:
            print(f"   error_type: {review_result.error_response.error_type}")
            print(
                f"   error_message: {review_result.error_response.error_message[:100]}..."
            )

        # ê²€ì¦: ì‹¤íŒ¨í•´ì•¼ í•˜ê³ , ì—ëŸ¬ê°€ ì‹ë³„ë˜ì–´ì•¼ í•¨
        assert review_result.success is False, (
            "Context limit ì´ˆê³¼ ì‹œ success=Falseì—¬ì•¼ í•©ë‹ˆë‹¤"
        )
        assert review_result.error_response is not None, "ì—ëŸ¬ ì‘ë‹µì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤"

        # ì—ëŸ¬ íƒ€ì… ê²€ì¦ - context limit ì—ëŸ¬ë¡œ ì—„ê²©í•˜ê²Œ ì‹ë³„
        assert review_result.error_response.error_type == "context_limit_exceeded", (
            f"ì—ëŸ¬ íƒ€ì…ì´ 'context_limit_exceeded'ì—¬ì•¼ í•©ë‹ˆë‹¤. "
            f"ì‹¤ì œ: {review_result.error_response.error_type}"
        )

        print("âœ… Google Gemini Context Limit ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì„±ê³µ!")

    except Exception as e:
        pytest.fail(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜ˆì™¸ ë°œìƒ: {e}")
